{"sha1": "77633f9683498aa87def1875af0b7ad9582adec2", "filename_exif": "Yes, Human Rights Practices Are Improving Over Time.pdf", "extension_exif": "PDF", "last_modified_exif": "2022:09:26 08:09:41+10:00", "create_date_exif": "2019:06:04 14:04:54+05:30", "access_date_exif": "2023:09:23 14:24:05+10:00", "modify_date_exif": "2022:09:26 08:09:41+10:00", "mime_type_exif": "application/pdf", "file_size_exif": 3330311, "title_exif": "", "path_components_exif": ["data"], "publication_date_exif": "", "author_exif": "", "organizational_unit_exif": "", "content": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS000305541900025X 868..881\n\n\nAmerican Political Science Review (2019) 113, 3, 868\u2013881\n\ndoi:10.1017/S000305541900025X \u00a9 American Political Science Association 2019\n\nLetter\nYes, Human Rights Practices Are Improving Over Time\nCHRISTOPHER J. FARISS University of Michigan\n\nTo document human rights, monitoring organizations establish a standard of accountability, or\na baseline set of expectations that states ought to meet in order to be considered respectful of human\nrights. If the standardofaccountabilityhasmeaningfully changed, then the categorizedvariables from\n\nhuman rights documents will mask real improvements. Cingranelli and Filippov question whether the\nstandard of accountability is changing and whether data on mass killings are part of the same underlying\nconceptual process of repression as other abuses. These claims are used to justify alternativemodels, showing\nno improvement in human rights. However, by focusing on the coding process, the authors misunderstand\nthat the standard of accountability is about how monitoring organizations produce documents in the first\nplace and not how academics use published documents to create data. Simulations and latent variables that\nmodel time in a substantively meaningful way validate the conclusion that human rights are improving.\n\nINTRODUCTION\n\nThe standard of accountability is the set of\nexpectations developed by human rights moni-\ntoring organizations about the specific re-\n\nsponsibilities that governments around the world have,\nand ought to meet, with respect to the treatment of\nindividuals. It isalso thecoreconcept fromatheoryabout\nhow the organizational structures and procedures of\nhuman rights monitoring organizations produce in-\nformation about state behaviors over time (Fariss 2014).\nIn short, the standard of accountability continues to\nevolve as activists, lawyers, jurists, norm entrepreneurs,\nregional human rights courts, NGOs, IGOs, government\nagents, and other actors call attention to state behaviors,\ncreate innovative legal arguments, and build new insti-\ntutions designed to protect the rights of individuals\n(e.g., Brysk 1994; Clark 2001; Dancy and Fariss 2017;\nSikkink 2017). If the standard of accountability has\nmeaningfully changed over time, then the categorized\nvariables from human rights documents will mask real\nimprovements in human rights over time (Fariss 2014,\n2018a, 2018b).\n\nInacritique,Cingranelli andFilippov (2018)question\nwhether the standard of accountability is changing and\nwhether data on mass killings are part of the same\nconceptual process of repression as other human rights\nabuses such as torture and political imprisonment. The\nauthors base their argument on amischaracterization of\n\nthe theory from Fariss (2014). Summarizing the theory,\nCingranelli and Filippov (2018, 1085) state that\n\u201c[h]uman rights scores may be inconsistent over time,\nbecause: (a) human rights reports have gotten longer,\nand more information, by itself, may have influenced\ncoders to assign lower scores; (b) coders may have ap-\npliedmore stringent standards inmore recent years; and\n(c) theremay be new types of critiques included inmore\nrecent reports.\u201d By focusing on how political scientists\ncode documents, Cingranelli and Filippov (2018) mis-\nunderstand that the standard of accountability is about\nthe original documentation process by monitoring\norganizations and not the academic coding process.1\n\nThe theoretical distinction between actors (docu-\nment producers versus academic coders) is important\nfor making conceptual distinctions between different\nindicators of repression and when introducing mod-\nifications to latent variable models. Building on the\nmischaracterization of the theory of standard of ac-\ncountability, Cingranelli and Filippov (2018) make two\nrelated claims that they use to justify two alternative\nlatent variable modeling decisions. First, the coding\nprocess for all the existing human rights data is po-\ntentially affected by the standard of accountability.\nSecond, data on mass killings are not part of the same\nunderlying concept of repression as other human rights\nabuses such as torture and political imprisonment and\nshould be considered independently. Cingranelli and\nFilippov (2018) use these claims to suggest that the\nlatent variable models of human rights presented by\nFariss (2014) aremisspecified.Then, using theestimates\nfrom one alternative latent variablemodel specification\nthat includes all variables and one that includes only\nstandards-based variables, Cingranelli and Filippov\n(2018) conclude that human rights are not improving\nover time.\n\nI first discuss the critique of the standard of ac-\ncountability as it relates to the documentation process\n\nChristopher J. Fariss , Assistant Professor, Department of Political\nScience, University of Michigan, cjfariss@umich.edu.\n\nSpecial thanks to Michael Kenwick and Kevin Reuning, who have\nprovided an immeasurable amount of assistance and support as I\nprepared this response. Much of the work builds on several joint\nmeasurement projects that are currently underway (Reuning, Ken-\nwick, and Fariss Forthcoming). I also acknowledge research support\nfrom the SSK (SocialScience Korea) Human Rights Forum, the\nMinistry of Education of the Republic of Korea, and the National\nResearch Foundation of Korea (NRF-2016S1A3A2925085). Repli-\ncation files are available at the American Political Science Review\nDataverse: https://doi.org/10.7910/DVN/EB8DD8.\n\nReceived:December12, 2017; revised: June29, 2018; accepted:March\n8, 2019; First published online: May 14, 2019.\n\n1 Clark and Sikkink (2013) argue that academic coders may be\ninfluenced by larger quantities and greater quality of information\nwhen categorizing reports,whereas Fariss (2014) shifts the conceptual\nfocus from academic coders to document producers.\n\n868\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://doi.org/10.1017/S000305541900025X\nhttps://orcid.org/0000-0001-9837-186X\nmailto:cjfariss@umich.edu\nhttps://doi.org/10.7910/DVN/EB8DD8\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\nconducted by monitoring organizations that generates\nqualitative reports and the coding process conducted by\nacademics that generates categorical data from those\nreports. I also discuss the use of evidence from data on\nmass killings in conjunction with data on other forms of\nhuman rights abuse. These discussions are important\nbecause they form the theoretical justification for the\ndifferent latent variable model specifications presented\ninFariss (2014)andhere.Second, Ipresenta simulation,\nwhich illustrates the identification problem in latent\nvariable models where all of the item-difficulty\nparameters vary year-to-year. The evidence from the\nsimulations demonstrates that the model suggested by\nCingranelli and Filippov (2018) is not identified with\nrespect to timebecause it resets theyearlyaverageof the\nlatent variable to zero no matter the values of the data.\nRelatedly, randomly generated data, as presented by\nCingranelli and Filippov (2018), do not meaningfully\nchange latent variable model estimates because the\nsimulated values only add random noise to the models,\nwhich average out to zero each year. Third, I present an\nupdated version of the latent variable model of human\nrights anduse construct validity andposteriorpredictive\nevidence to compare the two original models presented\ninFariss (2014) and the alternative versionpresentedby\nCingranelli and Filippov (2018). These validity assess-\nments show the substantive consequences of not ac-\ncounting for time in a substantively meaningful way.\nFourth, I present yearly estimates from several addi-\ntional latent variables models, which are based on dif-\nferent subsets of the available human rights variables\n(seeAppendixA).Nearly allmodels,with theexception\nof models that contain information about torture de-\nrived from the US State Department reports, show an\nimproving trend in human rights. These new model\ncomparisons reveal which variables are driving the\ndifferences between estimates from the changing\nstandard of accountability model and its alternatives.\nThese new results are also consistent with new expert-\ncoded human rights data fromVDEM (Coppedge et al.\n2014), which validates the conclusion that human rights\nare improving over time. Overall, what this evidence\ndemonstrates is not that the improvingyearlyaverageof\nhuman rights in (Fariss 2014) is being driven by large-\nscale event-based indicators, but rather, that certain\nstandards-based variables are masking the yearly\nimprovements across many indicators (see Appendix\nB) and the latent variables estimates because monitors\nare increasingly likely to observe and report insistences\nof torture and ill-treatment in more recent years. Ad-\nditional details are presented in the supplementary\nmaterial Appendix Sections A\u2013J.\n\nCONCEPTUAL FOUNDATIONS FOR HUMAN\nRIGHTS LATENT VARIABLES\n\nThe Documentation Process and Coding\nProcess of Human Rights\n\nThe goal of measurement is to define an operational\nprocedure that takes information and creates data free\n\nfrom conceptual (translational) error andmeasurement\nerror (Fariss andDancy 2017).Acategorization process\nsuch as the Political Terror Scale (PTS) (Gibney et al.\n2017) or theCIRIhuman rights project (Cingranelli and\nRichards 1999) is an operational procedure designed to\nbe consistently applied to human rights documents in\norder to categorize aggregated country-year human\nrights practices. Fortunately for these academic teams,\nlarge-scale monitoring efforts systematically produce\nyearly human rights reports that are publicly available\nand cover nearly every country in the world. The po-\nlitical science teams that work to categorize the in-\nformation contained in these human rights reports can\ntake advantage of the fact that these reports are pro-\nduced using a standardized process each year. This is\nwhat the human rights community means when they\nrefer to the PTS andCIRI variables as standards-based.\nConceptually, it is important to note that these stand-\nards are not in reference to the coding procedures used\nto code the data but rather the standardized procedures\nused by the monitoring organizations to produce the\nhuman rights reports each year. It is this standardized\ninformation which is then used by the political science\nteams to categorize information into human rights data.\nBut what if the standards used to produce the primary\nsource human rights documents change?\n\nThe theory of the standard of accountability helps\nanswer this question because it is focused on the or-\nganizational structures and procedures that are de-\nveloped and implemented to document human rights\nabuses by monitoring organizations such as Amnesty\nInternational and the US State Department. The PTS\nand CIRI teams have very little input into these orga-\nnizational processes. The categorical indicators coded\nfrom the reports are manifest of a complex process that\nbegins with the human rights abuses themselves, the\nobservation, collection, and corroboration of allega-\ntions about those human rights abuses, the organization\nof those allegations into a structured narrative account\ncontained within the country reports, and finally the\ncoding/categorization process of that content by aca-\ndemics. To compare categorical values, the CIRI and\nPTS teamsmust assume that the processes that build up\nto the publication of the human rights reports are\nconstant for each report, in every year and for every\ncountry, and that variation in the content of each report\nis only attributable to differences in the underlying\nhuman rights condition for each country-year unit.\nThough the categorized values coded from the human\nrights reports by PTS and CIRI reliably reflect the\ncontent of the human rights reports, these values arenot\nable to directly capture any differences in the processes\nthat lead up to their publication.\n\nThe theoretical distinction between actors (docu-\nment producers versus academic coders) is important\nfor making conceptual distinctions between different\nindicators of repression and when introducing mod-\nifications to latent variable models. In order to justify\nthe specification of their alternative latent variable\nmodel, Cingranelli and Filippov (2018, 1087) suggest\nthat the changing standard of accountability can affect\nthe coding process of the events-based variables. They\n\nYes, Human Rights Practices Are Improving Over Time\n\n869\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\nsuggest that\u201c[t]here is ahigher likelihoodnowthatmass\nkillings in remote places will be recorded. Coding rules\nfor recording mass killings may be changing. Coders\nmay have applied more stringent standards in more\nrecent years. And coding rules across mass killing re-\ncording projects may be becoming more or less con-\nsistent with one another.\u201d\n\nThese variables cover specific forms of repression,\nmostly related to state-sanctioned killing: mass killings,\nmass repression, genocide, politicide, executions,\nnegative-sanctions, or one-sided government killings.\nThe standard of accountability likely affects the docu-\nmentation used to code these variables as well. How-\never, unlike the CIRI, PTS, Hathaway, and ITT data\nprojects, the event-based variables are not direct cat-\negorizations of documents but rather are binary indi-\ncators that are coded 1 if sufficient documentary\ninformation exists in the historical record to support\nsuch a categorization. For the standards-based varia-\nbles, the documents are directly categorized. Because\nthe documents are never updated or revised, the\nstandards-based variables are rarely updated. For the\nevent-based variables, documentary evidence is taken\nfrommultiple sources andused to look for evidence that\na particular type of repressive event occurred. If new\ndocumentary evidence emerges about a specific type of\nrepressive event, the categorized value for the country-\nyear unit is updated. Thus, these are fundamentally\ndistinct categorization processes. The first categoriza-\ntion process relies exclusively on the content from the\nindividual country-year report. The second relies on\na set of documents and, for many of the variables\nconsidered in this paper, is updated and repeated when\nnew informationenters thehistorical record.The event-\nbasedcategorizationprocess is thereforeable toaddress\nvariation in the underlying documentation processes\nthat generates information because these variables are\neach based on set of different documents and are\nupdated periodically. The standards-based coding\nprocess cannot directly account for this variation.\n\nFariss (2014) does not argue that mass killing are\nrecordedmore accurately thanother forms of violations\nin any particular documentary source, when that doc-\numentary source is produced. Rather, the distinction\nbetween standards-based and events-based variables in\nFariss (2014) is about how the documentary evidence is\nused to create categorical data. Fariss (2014) dis-\ntinguishes between the direct categorization of the\ndocumentary evidence (standards-based variables) and\nthe broader use of documents to find evidence of\na specific type of event. It need not be the case that large\nscale events are recorded more accurately in the his-\ntorical record than other violations because evidence\nfor many repressive events does not necessarily enter\nthe historical record as they are occurring. It is therefore\nimportant to continue to update the historical source\nmaterial used to create event-based categorical varia-\nbles as all of the events-based coding teams have done\na various points in time (e.g., Eck and Hultman 2007;\nHarff 2003; Harff andGurr 1988; Rummel 1994; Taylor\nand Jodice 1983). The difference between the specifi-\ncation of the constant standard model and the changing\n\nstandard model presented in Fariss (2014) is based on\nthe difference in how these two types of variables are\ncategorized. The standard of accountability is likely\nchanging all of the documentary evidence used by the\ndifferent coding teamsbut theevent-basedvariables are\ncategorized usingmany sources and updated over time,\nwhich helps to account for bias from particular sources.\nThis makes the event-based variables suitable to act as\na baseline for comparison with the standards-based\nvariables that do not share this feature.\n\nThe Concept of Physical Integrity Rights: One\nor Two Dimensions?\n\nCingranelli and Filippov (2018) also suggest that large-\nscale killing events are a distinct repertoire of state-\nsanctioned repression in comparison with other forms\nof physical integrity abuses such as political imprison-\nment, and ill-treatment and torture because govern-\nmentsadoptdifferent tactics to implement thesepolices.\nAs such, they should be treated as independent\ndimensions in analysis. However, these types of re-\npressive practices are conceptually and empirically\nrelated to state-sanctioned practices that are associated\nwith disappearances, extra-judicial killings, and the\nlarge-scale occurrence of killings as well. This theo-\nretical understanding forms the basis for the primary\nconceptual definition of \u201crepression\u201d or violations of\n\u201cphysical integrity rights,\u201d which include arrests and\npolitical imprisonment, beatings and torture, extraju-\ndicial executions, mass killings, and disappearances, all\nof which are practices used by political authorities\nagainst those under their jurisdiction.\n\nThis argument by Cingranelli and Filippov (2018) is\nsimilar to the one made by McCormick and Mitchell\n(1997), who argued that physical integrity rights should\nbe considered along two dimensions: killing and dis-\nappearances, which often end in death, and torture and\npolitical imprisonment, which are about the treatment of\nthe living. In the article that introduced the four CIRI\nphysical integrity variables, Cingranelli and Richards\n(1999) argued against the two-dimensional conceptual-\nization and used a statistic from Mokken (1971) to\ndemonstrate the indicatorsof these four typesof physical\nintegrity violations scale together along one dimension.\n\nThe scaling result from Cingranelli and Richards\n(1999) is supported by additional evidence about the\nrelationshipbetweenallof theCIRIvariablespresented\nby Fariss and Schnakenberg (2014), which shows a high\ndegree of complementarity and no evidence of sub-\nstitution between the four physical integrity rights at the\naggregate country-year level, and in Schnakenberg and\nFariss (2014), which provided additional validation of\nthe scalability of the four physical integrity variables.\nFinally, Fariss (2014) discusses a multidimensional IRT\nmodel in the appendix of that article and finds no em-\npirical support for a second dimension from the 13\nindicators considered in that article. In summary, con-\ntrary to the argument from McCormick and Mitchell\n(1997) and now from Cingranelli and Filippov (2018),\nthere is no empirical evidence from Cingranelli and\nRichards (1999), Fariss and Schnakenberg (2014), or\n\nChristopher J. Fariss\n\n870\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\nSchnakenberg and Fariss (2014) that repressive tactics\nscale on more than one dimension at the country-year\nlevel of aggregation. This does notmean that, below the\ncountry-year level of aggregation, substitution between\nrepressive practices might be occurring or that different\ntactical choices are associated with specific forms of\nrepression, which is consistent with the argument about\nviolence in Colombia fromGuitie\u0301rrez-San\u0131\u0301n andWood\n(2017). It only means that empirically, these physical\nintegrity variables are conceptually related and are\nuseful for scaling and comparing country-year units.\n\nIt is important to further consider the aggregation of\ngovernment policies or tactics as they relate to the use\nand observability of different forms of repression.\nSubstantively, there is substantial evidence that certain\nforms of human rights abuses, what Cingranelli and\nFilippov (2018) label \u201clesser forms of abuse,\u201d were\nunder-reported in earlier periods, particularly during\nthe periods when more egregious forms of abuse were\nprevalent. If the presence of one repressive tactic\nreduces the probability that another tactic is observed\nby a monitoring organization or dampens the retribu-\ntion faced by a leader caught using the tactic, those\ntactics may be complements, which makes observing\neach type of abuse difficult as the scale of other\nabuses increases (Fariss and Schnakenberg 2014).\nThis is consistent with Brysk (1994, 681), who argues\nthat \u201c[i]ncidents of kidnapping and torture which\nwould register as human violations elsewhere did not\ncount in Argentina. The volume of worse rights abuses\nset a perverse benchmark and absorbed monitoring\ncapabilities.\u201d\n\nThis logic implicates how the documentation of\nabusesoccurs in respectful cases. For example, theCIRI\nhuman rights project codes the highly transparent case\nof Sweden as a state that uses ill-treatment and torture\nevery year since 2005 (Eck and Fariss 2018). What the\ninsights from Brysk (1994) and Eck and Fariss (2018)\nreveal is that certain forms of abuse are relatively easier\nto observe when the overall level of human rights abuse\nis low but relatively more difficult to observe when the\noverall level of human rights abuse is high. This is be-\ncause monitoring capacity is not limitless but is in-\ncreasingly effective as the volume of abuses decreases.\nThis seems to be especially the case for documenting\ninstances of ill-treatment and torture.\n\nAs a tactic, torture and ill-treatmentmay be intended\ntoextract information fromsome individuals,whereas it\nmay be used to the intimidation of others. Though the\ngoals of torture or the ability of the state to structure\ninstitutions that completely eliminate the practice likely\nvary, the overall aggregation of information about the\npractice at the country-year level is empirically related\nto other instances of physical integrity abuse (Brysk\n1994; Eck and Fariss 2018). Thus, it is more difficult for\nmonitoring organizations to detect torture in compar-\nison with the other forms of physical integrity rights\nabuse as the scale of abuses increases. Below, I dem-\nonstrate that, consistent with this logic, information\non torture and ill-treatment derived from the State\nDepartment reports is themost sensitive to the changing\nstandard of accountability relative to the other\n\nevent-based data but also all of the other standards-\nbased categorical indicators as well.\n\nSIMULATION ANALYSIS: CONSTANT\nDIFFICULTY PARAMETERS COMPARED TO\nTEMPORALLY VARYING DIFFICULTY\nPARAMETERS\n\nCingranelli and Filippov (2018) charge that Fariss\n(2014) failed to assess the assumptions of the two latent\nvariablesmodels. To support this claim, Cingranelli and\nFilippov (2018) create random-ordered categorical\nvariables and reestimate the latent variable model with\nthese simulated variables in place of the standards-\nbased variables. They wish to draw the inference that\nthe standards-based variables do not provide mean-\ningful information by comparing yearly mean point\nestimates. But this inference is not valid. Because the\nsimulated data are not generated from any underlying\nmodel related to the other data, Cingranelli and Fili-\nppov (2018) have just added random noise to the\nestimates. Unfortunately, there is nothing we can learn\nfrom this simulation other than what the unchanged\nevents-based variables already show. Though adding\nrandomdata to theunits in the latent variablemodelwill\nrandomly shift the position of some units, it will not\nchange the average for these units in each year.\n\nRelatedly, Cingranelli and Filippov (2018) state that\nFariss (2014, 1083) relies on \u201cstringent assumptions,\u201d\nwhich \u201cheavily weighted rare incidents of mass killings\nsuch as genocide.\u201d This is incorrect. The latent variable\nmodels in Fariss (2014) incorporate the event-based\nvariables in exactly the same way across specifications.\nThe standards-based variables are treated differently,\nbut it is not through the item-weights, but rather through\ntheir item-difficulty parameters. The term item-weights\nis usually used to describe the item-discrimination\nparameters in the IRT models, which are analogous\nto slope parameters in a logit or ordered-logit, whereas\nthe item-difficulty parameters are analogous to inter-\ncepts or cut-points. The assertion made by Cingranelli\nand Filippov (2018) is misleading for two reasons: first,\nbecause they do not clearly discuss which of the\nparameters they are criticizing, and second, because\nthey provide no evidence to support their claim about\nthe size of either the item-difficulty or item-\ndiscrimination parameters.\n\nThe country time-series plots that Cingranelli and\nFilippov (2018) provide are discussed without any\nsystematic statistical analysis. Contrary to their claim,\nthe evidence in these graphs supports theuseof both the\nevents-based and standards-based data to measure the\nsame theoretical concept of physical integrity because\nthey are strongly related even though they are estimates\nfromdifferent sets of human rights variables.Thus, each\nof the standards-based variables provides meaningful\ninformation for the placement of each of the country-\nyear units relative to all the others (see Appendix C).\nThe rest of the evidence for theCingranelli andFilippov\n(2018) critique is based on the estimates from two al-\nternative latent variable models that show that human\n\nYes, Human Rights Practices Are Improving Over Time\n\n871\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\nrights have not improved. However, the first of these\nalternativemodels is not identified with respect to time,\nwhich makes the latent variable estimates from this\nmodel not comparable year-to-year (country compar-\nisons within years are possible).\n\nI demonstrate this issue with a simulation. I set the\nnumber of unitsN5 30, the number of time periodsT5\n10, and the number of binary items J5 5. The simulation\ntakes an initial draw from u, the latent variable for each\nunit: ut,1 ~ N(22, 1). It takes the remaining draws from\nui,t ~ un,t211 ct1N(0,s), where ct is a constant value for\neach time period so that the average value of ut increases\nby 4\n\n9 over the10timeperiods,whichbeingsat22andends\nat 2. The innovation standard deviation is set tos5 0.05,\nwhich approximates this parameter from Schnakenberg\nand Fariss (2014). J 5 5 item-difficulty parameters\nare set to aj 5 0 and the item-discrimination parame-\nters are set to bj 5 1. The following data-generating\nprocess generates the simulated items for each unit:\nyi,t,j ~ Bernoulli(F(2(aj 1 bjui,t))) where F is the\n\ncumulative distribution function of the standard normal\ndistribution(Reuning,Kenwick,andFarissForthcoming).\n\nI estimate posterior distributions for the latent varia-\nbleswith the simulateddata in sixmodels.Thefirstmodel\nis a dynamic latent variable model with a single, fixed or\nconstant difficulty parameter that is estimated for eachof\nthe items (aj). Thismodelmatches the constant standard\nmodel from Fariss (2014). The other models are also\ndynamic but with a set of difficulty parameters (at,j)\nwhich are allowed to vary for eachof the 10 timeperiods.\nFor these models, at,j parameter is estimated for each of\nthe 10 time periods for 1, 2, 3, 4, or all 5 items, while only\na singleaj parameter is estimated for the remaining item\n(s) (i.e., one constantaj parameter is estimated for 4, 3, 2,\n1, or 0 items, respectively). Themodel that estimates the\nvarying difficulty parameters for all 5 items (0 constant)\nmatches the setup of the all-varying standard model\nproposedbyCingranelli andFilippov(2018).Themodels\nin between are similar to the changing standard of ac-\ncountability model (Fariss 2014).\n\nFIGURE 1. Simulation of Latent Variable Model Specifications\n\nThe dark points represent the true mean for each time period from the simulated data. The gray bars represent the posterior distribution for\neach timeperiodmean from themodels. Themodel on the lower right side is estimatedwith a time-specific item-difficulty parameter for every\nitem.Thismodel isnotable toestimate theover timechangebecause therearenoobserved indicatorsused to relate the latentestimatesyear-\nto-year. The model is therefore forced to center the mean for the units in each time period at zero. All of the other models are identified with\nrespect to time, which makes it possible to make over time comparisons of the latent variables estimated from these other models.\n\nChristopher J. Fariss\n\n872\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\nFigure1plots the truemean for each timeperiod from\nthe simulated data in dark points. The gray bars rep-\nresent the estimated posterior distribution for each time\nperiodmean. Themodel in the top left is estimatedwith\nconstant item-difficulty parameters, which is analogous\nto a standard dynamic latent variable model (dynamic\nwith respect to the latent trait for each unit but constant\nor fixed with respect to each item-difficulty parameter).\nThemodelon the lower right side is estimatedwith time-\nspecific item-difficulty parameters for all items, which is\nanalogous to the model proposed by Cingranelli and\nFilippov (2018).Thismodel isnot identifiedwith respect\nto time because it centers the mean for the units in each\ntime period at zero, which makes it impossible to make\nover time comparisons of the latent variables estimated\nfrom the model on the right. Any latent variable model\nthat allows all the item-difficulty parameters to vary\nover time will behave in this way. As long as the item-\ndifficulty parameter for at least one item is constant, the\nmodel recovers evidence for the change over time.Note\nin this simulation, the observed data are increasing on\naverage because they are generated from a latent trait\nthat is increasing over the 10 time periods, which is not\nthe case for the standards-based human rights data\n(Fariss 2014).\n\nFigure 2 demonstrates the ability of the models to\nestimate the latent mean across time periods as the\nnumber of constant item-difficulty parameters decrea-\nses to zero [the all-varyingmodel proposed byCingranelli\nand Filippov (2018)]. Like the other four models in\nFigure 1, the latent variablemodel that incorporates the\nchanging standard of accountability is specified by\nallowing some of the item-difficulty parameters to\nchange over time but not all of them. Unlike the all-\nvarying difficulty parameter model however, such\na model is identifiable with respect to time because it\nallows only some of the difficulty parameters to vary\nover time while keeping half of these parameters fixed\nor constant. The changing standard of accountability\ncan only be accounted for when information that it\ninfluences is assessed in relation to the information\ngenerated consistently over time. The model does this\nby assessing the yearly frequency of some of the\nstandards-based variables to the overall frequency of\nthe events-based variables.\n\nCOMPARING ESTIMATES FROM THREE\nLATENT VARIABLE MODELS\n\nTo estimate the latent variable model, each item or\ncategorized human rights variable is linked to the latent\ntrait\u2014the relative level of human rights respect of one\ncountry-unit relative to all the others\u2014using a gener-\nalized linear function. The latent variable model places\neach of the country-year units relative to one another\nalong a single interval-level dimension with a score of\n0 acting as the global average for all country-year units.\nAll country-year units are placed relative to this aver-\nage. The model proposed by Cingranelli and Filippov\n(2018) alsoplaces eachof the country-yearunits relative\nto one another along a single interval-level dimension\n\nwith a score of 0 acting as themean for each year, which\ncontrastswith theother latent variablemodels that have\na global mean for units across all years. Units are not\ncomparable between years for this model specification.\nThe all-varying standard model produces a flat trend\nline which, by coincidence, is similar, to the trend of the\nconstant standard model from Fariss (2014). This sim-\nilarityoccursbecause, in theall-varying standardmodel,\nit is not possible to estimate a change over time and, in\nthe constant standard model, there is not a change over\ntime due to the influence of the standards-based vari-\nables. Table 1 summarizes the specification of param-\neters for three competing models. Figure 3 displays the\ndistribution of the latent variable point estimates for\nthree models.\n\nCorrelationbetweenLatentVariableEstimates\n\nCingranelli and Filippov (2018) argue that the event-\nbased variables are responsible formost of the variation\nin the latent variable estimates. However, the\nstandards-based variables provide more information\nthan the event-based variables. Moreover, all of the\nlatent variable models, even the ones based on only\nsome of the observed variables, are strongly related to\none another. Figure 4 demonstrates high levels of\nagreement between estimates. This is because most of\nthe variation in the human rights indicators is cross-\n\nFIGURE 2. Correlation Between Estimate\nLatent Trait and Simulated Trait\n\nEachbarcorresponds toeachof themodelspresented inFigure1.\nThemodel on the right most side is estimated with a time-specific\nitem-difficulty parameter for every observed item and is similar to\nthe model suggested by Cingranelli and Filippov (2018). This\nmodel is not able to estimate the over time change because there\nare no observed indicators used to relate the latent estimates\nyear-to-year. Increasing the number of constant difficulty-\nparameters relative to the number of varying difficulty parameters\nis useful because it increases the amount of information used to\nrelate the estimates of the latent trait across time periods.\n\nYes, Human Rights Practices Are Improving Over Time\n\n873\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\nsectional. Key differences emerge when considering\ntemporal variation as the simulation from above\nreveals. Cingranelli and Filippov (2018, 1086) present\none of these relationships, reporting the squared cor-\nrelation fromabivariate linear regression. They use this\nstatistic to suggest that the estimates from the latent\n\nvariable generated from only the event-based variables\nexplain most of the variance in the latent variable from\nthemodel that uses all the variables. This is notwhat the\ncorrelation coefficient here reveals because each of the\ndifferent latent variables is not independent of one\nanother (even when they are estimated with non-\n\nTABLE 1. Summary of Prior Distributions for Latent Variable and Model Level Parameter Estimates\n\nParameters All-varying standard Constant standard Changing standard\n\nCountry-year latent variable (first year) ui1 ~ N(0, 1) ui1 ~ N(0, 1) ui1 ~ N(0, 1)\nCountry-year latent variable (other years) uit ~ N(uit21, s) uit ~ N(uit21, s) uit ~ N(uit21, s)\nUncertainty of latent variable s ~ U(0, 1) s ~ U(0, 1) s ~ U(0, 1)\nEvent-based item cut-points (constant) \u2014 ajk ~ N(0, 4) ajk ~ N(0, 4)\nEvent-based item cut-points (first year) a1jk ~ N(0, 4) \u2014 \u2014\n\nEvent-based item cut-points (other years) atjk ~ N(at21,jk, 4) \u2014 \u2014\n\nStandards-based item cut-points (constant) \u2014 ajk ~ N(0, 4) \u2014\n\nStandards-based item cut-points (first year) a1jk ~ N(0, 4) \u2014 a1jk ~ N(0, 4)\nStandards-based item cut-points (other years) atjk ~ N(at21,jk, 4) \u2014 atjk ~ N(at21,jk, 4)\nSlope bj ~ Gamma(4, 3) bj ~ Gamma(4, 3) bj ~ Gamma(4, 3)\n\nCingranelli and Fillippov (2018) Fariss (2014) Fariss (2014)\n\nFIGURE 3. Distributions of Point Estimates From Three Competing Models\n\nThe interquartile range is containedwithin theboxeswith themedianvalueat thecenter line.Thedashed lines represented thevaluesbeyond\nthe interquartile range (plots do not incorporate uncertainty). The model proposed by Cingranelli and Filippov (2018) (left) produces a very\nsimilar trend to theconstant standardmodel fromFariss (2014) (middle) because in theCingranelli andFilippov (2018)model it is not possible\nto estimate a change over time. In the constant standard model, there is not a change over time because of the influence of the standards-\nbasedvariables.Because themodel proposedbyCingranelli andFilippov (2018) resets themeanestimate for all the countrieseachyear, the\nmean estimate can never move away from zero. Small changes year-to-year are due to new states that enter the dataset in the later years.\n\nChristopher J. Fariss\n\n874\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\noverlapping sets of human rights variables). The high\ncorrelation between the different latent variable esti-\nmates occurs because each of the indicators is manifest\nof the sameunderlyingconcept.Thoughnot reportedby\nCingranelli and Filippov (2018), the correlation co-\nefficient is smaller than the same statistic from a latent\nvariablemodel that is based on just the standards-based\nvariables and the latent variable based on all of the\n\nitems. This is because there are more standards-based\nvariables than event-based variables and because there\nare more categories for each of the standards-based\nvariables than for the events-based variables, which all\nhappen to be binary. Because the event-based variables\nand standards-based variables are both capturing evi-\ndenceof the sameunderlyingphysical integrity concept,\nthey are all related and strongly correlated. Even\n\nFIGURE 4. Correlation between Latent Variables Estimates from Five Models\n\nCorrelations between five different latent variable estimates reveals a high level of agreement between the different model specifications\nincluding models with only events-based or standards-based variables. The x-axis and y-axis are the latent variable estimates from the row\nand column latent variables estimates. Though substantively meaningful differences exists between time periods for these estimates, the\nhigh levelofagreementbetweenestimates indicates thateach latentvariableestimate is tapping into thesameunderlyingconceptofphysical\nintegrity abuse.Evenconstant standardmodels that useonly events-based variable or standards-based variables (but not) both are strongly\ncorrelated, which is evidence that all of these variables are tapping into the same underlying concept. Note that, for the period 1946\u201375, the\ncorrelationbetween the latent variablepoint estimatesbasedon just theevent-based itemand the latent variablepoint estimates basedonall\nof the items is approximately one because there are not standards-based variables as part of the model until 1976.\n\nYes, Human Rights Practices Are Improving Over Time\n\n875\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\nconstant standard models that use only events-based\nvariable or standards-based variables (but not both) are\nstrongly correlated, which evidences that all variables\nare tapping into the same underlying theoretical con-\ncept. Appendix E discusses additional issues of con-\nstruct validity, andAppendix F discusses why the latent\nvariables estimates from 1946 to 1975 are not from an\nextrapolation or interpolation.\n\nIdentifying the Top One Percent Worst Cases\n\nToassess thevalidityof the threecompetingmodels (all-\nvarying standard, constant standard, and changing\nstandard), I consider the ability of the latent variable\nestimates fromeachmodel to categorize theworst 1%of\ncountry-year cases each year. Figure 5 shows that the\nmodel proposed by Cingranelli and Filippov (2018)\nsuggests that the worst cases of human rights abuse are\nhappening in the most recent years for which we have\ndata, while both the constant standard model and\nchanging standard of accountability model suggest that\nearlier decades contain the worst cases of abuse.\n\nThe top 20 worst cases for the Cingranelli and Fili-\nppov (2018) model are Sudan 1999\u20132015 and Syria\n2013\u201315.These are indeed caseswith poorhuman rights\npractices; however, compare these cases with those\n\nidentified by the changing standard of accountability\nmodel: China 1968\u201371; Uganda 1976; Afghanistan;\n1980\u201387; Sudan 1959, 1965\u201366; and Iran 1982\u201385. The\nconstant standard model and changing standard model\nare in close agreement about which cases are in the top-\n1% worst because they are specified with respect to\ntime.Abinary indicator forwhether or not the case falls\nin this worst case category for these two models cor-\nrelates at about 0.85. The same indicator for the all-\nvarying model correlates with either the constant\nstandard model or changing standard model at about\n0.50 or 0.43, respectively. The all-varying standard\nmodel leads to an inference that the worst levels of\nhuman rights abuse have just occurred. Though\na careful analysis of each case is beyond the scope of this\narticle, it is important to highlight that the cases selected\nby the Cingranelli and Filippov (2018) model are arti-\nfacts of the resetting of themean to zero for each year of\nestimates. The worst cases today are forced further\ndown into the negative portion of the latent variable\nspace because these positions are not estimated relative\nto the units in previous years but only the units in the\nsame year. If there are more good or mediocre cases in\na given year, then the bad cases need to be placed\nfurther away from the mean zero to give space to these\nother cases. The all-varying standard model proposed\n\nFIGURE 5. Concurrent Validity Assessment of the Top One Percent Worst Cases of Human\nRights Abuse\n\nStacked units in the barplot are the country-years that have the 1% worst scores from three models (all-varying model, constant standard\nmodel, changingstandardmodel). Theconstant standardmodelandchangingmodel are in closeagreementaboutwhichcasesare in the top\n1% worst.\n\nChristopher J. Fariss\n\n876\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\nbyCingranelli and Filippov (2018) leads to an inference\nthat the worst levels of human rights abuse have just\noccurred or are possibly even yet to come because it is\nnot identified with respect to time.\n\nPosterior Predictions of the Yearly Means for\nHuman Rights Variables\n\nFigure 6 displays the differences in correlation coef-\nficients calculated between the yearly mean for each\nof the 16 human rights variables and the estimated\nyearly mean of one of the three latent variables. The\npositive differences demonstrate the greater ex-\nplanatory ability of the changing standard of ac-\ncountability model relative to the all-varying model\n\nand constant standard model. The all-varying stan-\ndard model does poorly because it resets the mean\nvalue of the latent estimate to zero each year, so it is\nunable to account for changes over time for any\nvariables except for the Rummel and Harff and Gurr\nevents-based variables.\n\nAlternative Constant Standard Estimates\nShow Improvements Over Time\n\nCingranelli and Filippov (2018) report that amodel with\nonly standards-based variables shows a stagnant trend in\nhuman rights respect over time. This is true. However,\nnot all of the standards-based variables show a stagnant\ntrend in their original categorical form (seeAppendixB)\n\nFIGURE6. SpearmanCorrelationBetweenYearlyObservedVariableMeansandLatentVariableMeans\n\nEachpaneldisplays thedifference inSpearmancorrelationcoefficientscalculatedbetween theyearlymean for thehumanrightsvariableand\nestimated yearly mean of one of the three latent variables. Positive values for either distribution indicate a stronger relationship between the\nyearly mean for the human rights variable and the estimated mean from the changing standard of accountability model. Negative values\nindicate a stronger relationship for either the all-varying standard model (left distribution) or the constant standard model (right distribution)\ncompared with the changing standard of accountability model.\n\nYes, Human Rights Practices Are Improving Over Time\n\n877\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\noraspartofaconstant standard latentvariablemodel.To\nunpack the difference between the yearly averages for\nthe changing standard model and the constant standard\n\nmodel fromFariss (2014), I estimate alternative versions\nof the constant standard of accountability model that\nmake use of only the standards-based variables. The first\n\nFIGURE7. Trends in Latent Variable Estimates forModelsBased on Just theStandards-BasedHuman\nRights Variable Over Time Using the Constant Standard Model Specification from Fariss (2014)\n\nAll of themodels are estimatedwith constant item-difficulty cut-points (constant standardof accountability). The baselinesmodels beginwith\nthe PTSHRW, ITT torture, and CIRI political imprisonment. These variables change the least relative to the baseline event-based variables\n(see Figure 4, Figure 5, and Appendix F in Fariss (2014) for evidence for this ordering). Beginning from the upper left panel, one additional\nstandards-based variable is added to the latent variable model in order: 31CIRI Disappearance, 41 PTS Amnesty, 51CIRI Extrajudicial\nKilling, 6 1 Hathaway Torture, 8 1 CIRI torture, and finally 9 1 PTS State Department.\n\nChristopher J. Fariss\n\n878\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\nmodel includes the ITT tortureand ill-treatment variable\nand the CIRI political imprisonment variable, which\nFariss (2014) shows are consistently documented year-\nto-year relative to the frequencies of the event-based\nvariables included in the standard of accountability\nmodel. I then estimate the constant standard latent\nvariable models (one intercept or one set of cut-points\n\nper item), adding in new items in the following order:\nCIRIDisappearance, PTSAmnesty, CIRI Extrajudicial\nKilling, Hathaway torture, CIRI torture, and finally PTS\nState Department.\n\nVariables most sensitive to the changing standard of\naccountability are the CIRI torture, PTS State De-\npartment, and Hathaway torture variables. Only when\n\nFIGURE 8. Trends in Latent Variable Estimates for Models Based on the Event-Based Human Rights\nVariables Over Time with an Additional Standards-Based Human Rights Variable Over Time Using the\nConstant Standard Model Specification from Fariss (2014)\n\nAll of themodels are estimatedwith constant item-difficulty cut-points (constant standardof accountability). The baselinesmodels beginwith\nthesevenevent-basedvariablesand thenoneadditional standards-basedvariables isadded in thesameorderasaboveandbasedonFariss\n(2014) (see Appendix D for the statistics that demonstrate the relative strength of the change over time for the standards-based items).\nBeginning from the upper left panel, one additional standards-based variable is added to the latent variable model in order: 7 items1 PTS\nHRW(notshownfor space reasons),8 items1 ITT torture,9 items1CIRIPolitical Imprisonment, 10 items1CIRIDisappearance,11 items1\nPTSAmnesty, 12 items1CIRI Extrajudicial Killing, 13 items1HathawayTorture, 14 items1CIRI torture, and finally 15 items1PTSState.\n\nYes, Human Rights Practices Are Improving Over Time\n\n879\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\nall of these observed variables are included in the es-\ntimation of the yearly average of the latent variable,\ndoes the trend line flatten out and become stagnant in\nFigure 7. The reduction in the slope of the latent var-\niablemodel is similar to the changewhen the standards-\nbased variables are added to the constant standard\nmodel starting with the seven event-based variables in\nFigure 8. Yearly patterns suggest that the Amnesty\nInternational reports are more consistently produced\nyear-to-year than the StateDepartment reports relative\nto the event-based variables. Within State Department\nreports, torture is the topic most sensitive to the affects\nof the changing standard of accountability (see the\nAppendix D for graphs of the yearly cut-points and\nprobabilities of each category of all of human rights\nvariables). Thus, it may bemore difficult formonitoring\norganizations to detect torture and ill-treatment in\ncomparison with the other forms of physical integrity\nrightsabuseas the scaleofotherabuses increases (Brysk\n1994) and easier as the scale decreases (Eck and Fariss\n2018). Appendix G andAppendix H provide details on\ncase study designs for comparing human rights\ninformation.\n\nVDEM Human Rights Variables Show\nImprovement Over Time\n\nFinally, in Figure 9, the VDEM torture and killing\nvariables show a substantial increase in respect after the\nend of the Cold War, which is discussed in another\nresponse to Cingranelli and Filippov (2018) (Fariss\n2018a). The trend from the VDEM human rights var-\niables are consistent with the latent human right\n\nvariable that incorporates the changing standard of\naccountability (Fariss 2018a) and the new trends pre-\nsented in this section. Appendix I presents the latent\nvariable trends over time for democracies and non-\ndemocracies, and Appendix J reviews the suggestions\nfor using the latent variable estimates in applied\nresearch.\n\nCONCLUSION\n\nHuman rights estimates developed by Fariss (2014) and\nextended in this article support the conclusion that\nhuman rights practices are improving. These new\nfindingsareonlypossiblebecauseof theyearsof reliable\ncoding conducted by the coding teams discussed above.\nUntil the publication of the theory of the changing\nstandard of accountability and the new latent variable\nestimates by Fariss (2014), the academic discourse\naround human rights progress was becoming in-\ncreasingly pessimistic (e.g., Hopgood 2013; Posner\n2014).This is because, for the pastfifteen years, scholars\nhave puzzled over the stagnating trend in country-year\nhuman rights and the negative correlation betweenUN\nhuman rights treaty ratifications and human rights (e.g.,\nHafner-Burton and Tsutsui 2005; Hathaway 2002). But\nthese negative patterns are not valid because they did\nnot account for changes in the source material used to\ngenerate the categorical data (Fariss 2014, 2018a, 2018b;\nFariss and Dancy 2017). Thus, there is reason for new\nhope, new theorizing, and new data collection, which is\nthe promise of the science of human rights (Schna-\nkenberg and Fariss 2014).\n\nFIGURE 9. Yearly Average for the Two Expert-Coded V-DEM Physical Integrity Variables From 1946 to\n2015 (Coppedge et al. 2014)\n\nThe upward trend in human rights respect after the end of Cold War is consistent with the pattern of the latent variable that accounts for the\nchanging standard of accountability reported in Fariss (2014). These similar patterns provide evidenceof the convergent validity of the latent\nhuman rights variable that incorporates the changing standard of accountability.\n\nChristopher J. Fariss\n\n880\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\nSUPPLEMENTARY MATERIAL\n\nTo view supplementary material for this article, please\nvisit https://doi.org/10.1017/S000305541900025X.\n\nReplication materials can be found on Dataverse at:\nhttps://doi.org/10.7910/DVN/EB8DD8.\n\nREFERENCES\n\nBrysk, Alison. 1994. \u201cThe Politics of Measurement: The Contested\nCount of the Disappeared in Argentina.\u201dHuman Rights Quarterly\n16 (4): 676\u201392.\n\nCingranelli, David L., and David L. Richards. 1999. \u201cMeasuring the\nLevel, Pattern, and Sequence of Government Respect for Physical\nIntegrity Rights.\u201d International Studies Quarterly 43 (2): 407\u201317.\n\nCingranelli,DavidL., andMikhailFilippov.2018.\u201cAreHumanRights\nPractices Improving?\u201d American Political Science Review 112 (4):\n1083\u20139.\n\nClark, Ann Marie. 2001. Diplomacy of Conscience. Princeton, NJ:\nPrinceton University Press.\n\nClark, Ann Marie, and Kathryn Sikkink. 2013. \u201cInformation Effects\nandHumanRightsData: Is theGoodNewsabout IncreasedHuman\nRights Information Bad News for Human Rights Measures?\u201d\nHuman Rights Quarterly 35 (3): 539\u201368.\n\nCoppedge, Michael, John Gerring, Stafan I. Lindberg, Jan Teorell,\nDanielPemstein,EitanTzelgov,Yi tingWang,AdamGlynn,David\nAltman, Michael Bernhard, M. Steven Fish, Allen Hicken, Kelly\nMcMann, Pamela Paxton, Megan Reif, Svend-Erik Skaaning, and\nJeffrey Staton. 2014. \u201cV-Dem: A New Way to Measure De-\nmocracy.\u201d Journal of Democracy 25 (3): 159\u201369.\n\nDancy, Geoff, and Christopher J. Fariss. 2017. \u201cRescuing Human\nRights Law from International Legalism and its Critics.\u201d Human\nRights Quarterly 39 (1): 1\u201336.\n\nEck, Kristine, and Christopher J. Fariss. 2018. \u201cIll Treatment and\nTorture in Sweden: A Critique of Cross-Case Comparisons.\u201d Hu-\nman Rights Quarterly 40 (3): 591\u2013604.\n\nEck, Kristine, and Lisa Hultman. 2007. \u201cViolence against Civilians in\nWar.\u201d Journal of Peace Research 44 (2): 233\u201346.\n\nFariss,ChristopherJ. 2014.\u201cRespect forHumanRightsHasImproved\nOver Time: Modeling the Changing Standard of Accountability in\nHumanRightsDocuments.\u201dAmericanPolitical ScienceReview 108\n(2): 297\u2013318.\n\nFariss,Christopher J. 2018a.\u201cAreThingsReallyGettingBetter?How\nto Validate Latent Variable Models of Human Rights.\u201d British\nJournal of Political Science 48 (1): 275\u201382.\n\nFariss, Christopher J. 2018b. \u201cHumanRights Treaty Compliance and\nthe Changing Standard of Accountability.\u201d British Journal of Po-\nlitical Science 48 (1): 239\u201372.\n\nFariss, Christopher J. 2019. \u201cYes, Human Rights Practices Are Im-\nproving Over Time.\u201d Harvard Dataverse V1. https://doi.org/\n10.7910/DVN/EB8DD8.\n\nFariss, Christopher J., andGeoffDancy. 2017. \u201cMeasuring the Impact\nof Human Rights: Conceptual and Methodological Debates.\u201d\nAnnual of Law and Social Science 13: 273\u201394.\n\nFariss, Christopher J., and Keith Schnakenberg. 2014. \u201cMeasuring\nMutual Dependence between State Repressive Actions.\u201d Journal\nof Conflict Resolution 58 (6): 1003\u201332.\n\nGibney, Mark, Linda Cornett, Reed Wood, Peter Haschke, Daniel\nArnon, and Attilio Pisano\u0300. 2017. \u201cThe Political Terror Scale\n1976\u20132016.\u201dPoliticalTerrorScale. http://www.politicalterrorscale.org/.\n\nGuitie\u0301rrez-San\u0131\u0301n, Francisco, and Elisabeth Jean Wood. 2017. \u201cWhat\nShould We Mean by \u2018Pattern of Political Violence\u2019? Repertoire,\nTargeting, Frequency, and Technique.\u201d Perspectives on Politics 15\n(1): 20\u201341.\n\nHafner-Burton, Emilie M., and Kiyoteru Tsutsui. 2005. \u201cHuman\nRights in a Globalizing World: The Paradox of Empty Promises.\u201d\nAmerican Journal of Sociology 110 (5): 1373\u2013411.\n\nHarff, Barabara. 2003. \u201cNo Lessons Learned from the Holocaust?\nAssessingRisksofGenocideandPoliticalMassMurdersince1955.\u201d\nAmerican Political Science Review 97 (1): 57\u201373.\n\nHarff, Barbara, andTedR.Gurr. 1988. \u201cTowardEmpirical Theory of\nGenocides and Politicides: Identification and Measurement of\nCases since 1945.\u201d International Studies Quarterly 32 (3): 359\u201371.\n\nHathaway, Oona A. 2002. \u201cDo human Rights Treaties Make a Dif-\nference?\u201d The Yale Law Journal 111 (8): 1935\u20132042.\n\nHopgood, Stephen. 2013.TheEndtimes ofHumanRights. Ithaca,NY:\nCornell University Press.\n\nMcCormick, James M., and Neil J. Mitchell. 1997. \u201cHuman Rights\nViolations, Umbrella Concepts, and Empirical Analysis.\u201d World\nPolitics 49 (4): 510\u201325.\n\nMokken, Rob J. 1971.ATheory and Procedure of Scale Analysis. The\nHague: Mouton.\n\nPosner, Eric A. 2014. The Twilight of Human Rights Law. Oxford\nUniversity Press.\n\nReuning, Kevin, Michael R. Kenwick, and Christopher J. Fariss.\nForthcoming. \u201cExploring the Dynamics of Latent Variable Mod-\nels.\u201d Political Analysis. Accepted.\n\nRummel,Rudolph J. 1994.Death byGovernment:Genocide andMass\nMurder in the Twentieth Century. New Brunswick, NJ: Transaction\nPublishers.\n\nSchnakenberg, Keith E., and Christopher J. Fariss. 2014. \u201cDynamic\nPatternsofHumanRightsPractices.\u201dPolitical ScienceResearchand\nMethods 2 (1): 1\u201331.\n\nSikkink, Kathryn. 2017. Evidence of Hope. Princeton, NJ: Princeton\nUniversity Press.\n\nTaylor,CharlesLewis,andDavidA.Jodice.1983.WorldHandbookof\nPolitical and Social Indicators. Vol. 2, 3rd edition. Political Protest\nand Government Change. New Haven: Yale University Press.\n\nYes, Human Rights Practices Are Improving Over Time\n\n881\n\nD\now\n\nnl\noa\n\nde\nd \n\nfr\nom\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne.\n A\n\nus\ntr\n\nal\nia\n\nn \nN\n\nat\nio\n\nna\nl U\n\nni\nve\n\nrs\nity\n\n, o\nn \n\n19\n Ju\n\nl 2\n02\n\n1 \nat\n\n 0\n2:\n\n35\n:1\n\n8,\n s\n\nub\nje\n\nct\n to\n\n th\ne \n\nCa\nm\n\nbr\nid\n\nge\n C\n\nor\ne \n\nte\nrm\n\ns \nof\n\n u\nse\n\n, a\nva\n\nila\nbl\n\ne \nat\n\n h\ntt\n\nps\n://\n\nw\nw\n\nw\n.c\n\nam\nbr\n\nid\nge\n\n.o\nrg\n\n/c\nor\n\ne/\nte\n\nrm\ns.\n\n h\ntt\n\nps\n://\n\ndo\ni.o\n\nrg\n/1\n\n0.\n10\n\n17\n/S\n\n00\n03\n\n05\n54\n\n19\n00\n\n02\n5X\n\nhttps://doi.org/10.1017/S000305541900025X\nhttps://doi.org/10.7910/DVN/EB8DD8\nhttps://doi.org/10.7910/DVN/EB8DD8\nhttps://doi.org/10.7910/DVN/EB8DD8\nhttp://www.politicalterrorscale.org/\nhttps://www.cambridge.org/core\nhttps://www.cambridge.org/core/terms\nhttps://doi.org/10.1017/S000305541900025X\n\n\tYes, Human Rights Practices Are Improving Over Time\n\tINTRODUCTION\n\tCONCEPTUAL FOUNDATIONS FOR HUMAN RIGHTS LATENT VARIABLES\n\tThe Documentation Process and Coding Process of Human Rights\n\tThe Concept of Physical Integrity Rights: One or Two Dimensions?\n\n\tSIMULATION ANALYSIS: CONSTANT DIFFICULTY PARAMETERS COMPARED TO TEMPORALLY VARYING DIFFICULTY PARAMETERS\n\tCOMPARING ESTIMATES FROM THREE LATENT VARIABLE MODELS\n\tCorrelation between Latent Variable Estimates\n\tIdentifying the Top One Percent Worst Cases\n\tPosterior Predictions of the Yearly Means for Human Rights Variables\n\tAlternative Constant Standard Estimates Show Improvements Over Time\n\tVDEM Human Rights Variables Show Improvement Over Time\n\n\tCONCLUSION\n\tSUPPLEMENTARY MATERIAL\n\n\n"}